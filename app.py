import streamlit as st
import torch
import numpy as np
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
import os

# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ---
try:
    from models import AttentionUNet, TransUNetSkip
except ImportError:
    st.error("Error: 'model_definitions.py' not found.")

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Skin Lesion Dashboard", layout="wide")
st.markdown("<h1 style='text-align: center;'>ğŸ”¬ Skin Lesion Analysis Dashboard</h1>", unsafe_allow_html=True)
st.write("---")

# 2. Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø£ÙŠØ³Ø±
st.sidebar.header("Configuration")
model_type = st.sidebar.selectbox("Architecture", ("Attention U-Net", "TransUNet Skip"))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
@st.cache_resource
def load_model(m_type):
    if m_type == "Attention U-Net":
        model = AttentionUNet().to(device)
        path = "best_attention_unet.pth" 
    else:
        model = TransUNetSkip().to(device)
        path = "best_transunet_skip.pth"
    
    if os.path.exists(path):
        model.load_state_dict(torch.load(path, map_location=device))
        model.eval()
    return model

# 4. Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª (Ù…Ù† ÙƒÙˆØ¯Ùƒ)
val_transform = A.Compose([
    A.Resize(256, 256),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2()
])

# 5. Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
uploaded_file = st.file_uploader("Upload Image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    image_np = np.array(image)

    with st.spinner('Processing...'):
        model = load_model(model_type)
        input_tensor = val_transform(image=image_np)['image'].unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            # Ø¹ØªØ¨Ø© Ø§Ù„ØªØ«Ø¨ÙŠØª 0.5 Ø¨Ø±Ù…Ø¬ÙŠØ§Ù‹
            pred_mask = (output[0, 0] > 0.5).cpu().numpy().astype(np.uint8)

    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ± Ù„Ù„Ø¹Ø±Ø¶
    # Ø£- Ø§Ù„Ù…Ø§Ø³Ùƒ (Ø£Ø¨ÙŠØ¶ ÙˆØ£Ø³ÙˆØ¯)
    mask_resized = np.array(Image.fromarray(pred_mask).resize(image.size, resample=Image.NEAREST))
    mask_pil = Image.fromarray(mask_resized * 255)

    # Ø¨- Ø§Ù„Ù€ Overlay (Ø¯Ù…Ø¬ Ø´ÙØ§Ù)
    overlay_np = image_np.copy()
    overlay_np[mask_resized == 1] = [255, 0, 0] # ØªÙ„ÙˆÙŠÙ† Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙˆØ±Ù… Ø¨Ø§Ù„Ø£Ø­Ù…Ø±
    final_overlay = Image.blend(image, Image.fromarray(overlay_np), alpha=0.4)

    # --- 6. Ø§Ù„Ø¹Ø±Ø¶ ÙÙŠ 3 Ø£Ø¹Ù…Ø¯Ø© Ø¬Ù†Ø¨Ø§Ù‹ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨ ---
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("### ğŸ“· Original")
        st.image(image, use_container_width=True)

    with col2:
        st.markdown("### ğŸ­ Binary Mask")
        st.image(mask_pil, use_container_width=True)

    with col3:
        st.markdown("### ğŸ¯ Overlay Result")
        st.image(final_overlay, use_container_width=True)
    
    st.success(f"Successfully analyzed using {model_type}")